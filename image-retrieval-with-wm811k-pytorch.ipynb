{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Contents\nThank you for viewing this notebook.\nUsing WM-811K dataset, I will try image retrieval task. This notebook aims to implement the code with `PyTorch Metric Learning` library. This offers us the easiest way to build metric learning model and image search methods. \n\nYou will find the simple and effective implementation!\n\n### Preprocess(minimum)\nWM-811K dataset containes the number of 811K data. However, there are only 25K data with specified labels. I will extract these with some other prerprocessing as well.\n\n### Model, Dataset class definition\n- Model: The most simple convnet with triplet loss\n- Dataset: It returns X(torch.Tensor) and y(int). Yes, this is a kind of supervised learning.\n\n### Train\nWith `trainer` API, I simply executed model training in metric learning way.\n\n### Inference\n- image retrieval with nearest neighbor search\n\n### Some experiments","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-31T02:37:15.441407Z","iopub.execute_input":"2023-03-31T02:37:15.442209Z","iopub.status.idle":"2023-03-31T02:37:15.486637Z","shell.execute_reply.started":"2023-03-31T02:37:15.442100Z","shell.execute_reply":"2023-03-31T02:37:15.485329Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/wm811k-wafer-map/LSWMD.pkl\n","output_type":"stream"}]},{"cell_type":"markdown","source":"It's ok when you see the message,`/kaggle/input/wm811k-wafer-map/LSWMD.pkl`.  \n\n上記実行後、`/kaggle/input/wm811k-wafer-map/LSWMD.pkl`と表記が出ればok\n\n# Preprocessing, 前処理","metadata":{}},{"cell_type":"code","source":"import os\nimport warnings\nfrom pathlib import Path\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nprint(os.listdir(\"../input\"))\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:37:15.489289Z","iopub.execute_input":"2023-03-31T02:37:15.489828Z","iopub.status.idle":"2023-03-31T02:37:16.785666Z","shell.execute_reply.started":"2023-03-31T02:37:15.489778Z","shell.execute_reply":"2023-03-31T02:37:16.783768Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"['wm811k-wafer-map']\n","output_type":"stream"}]},{"cell_type":"code","source":"# It takes around 2 minutes on Kaggle notebook.\ndf = pd.read_pickle(\"../input/wm811k-wafer-map/LSWMD.pkl\")\nprint(df.info())\ndisplay(df.head(3))","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:37:16.787719Z","iopub.execute_input":"2023-03-31T02:37:16.788546Z","iopub.status.idle":"2023-03-31T02:38:10.771213Z","shell.execute_reply.started":"2023-03-31T02:37:16.788494Z","shell.execute_reply":"2023-03-31T02:38:10.768022Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0;31m# expected \"IO[bytes]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas.indexes'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/compat/pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1087\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mload_binstring\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBINSTRING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_binstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36m_decode_string\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0x9a in position 6: ordinal not in range(128)","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/847477852.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# It takes around 2 minutes on Kaggle notebook.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/wm811k-wafer-map/LSWMD.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/compat/pickle_compat.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/pickle.py\u001b[0m in \u001b[0;36mload_binint1\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_binint1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBININT1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_binint1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# label extraction  e.g.)[Loc] → Loc　 @failureType, trianTestLabel column\nf_squeeze = lambda x: str(np.squeeze(x))\ndf[\"failureType\"] = df[\"failureType\"].map(f_squeeze)\ndf[\"trianTestLabel\"] = df[\"trianTestLabel\"].map(f_squeeze)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.772357Z","iopub.status.idle":"2023-03-31T02:38:10.773422Z","shell.execute_reply.started":"2023-03-31T02:38:10.773162Z","shell.execute_reply":"2023-03-31T02:38:10.773186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# drop the row data with no specified label\neliminate_list = ['none', '[]']\ndf_with_label = df.query(f\"failureType not in {eliminate_list}\")\nprint(f\"{len(df_with_label)}\")\nprint(\"Label list: \", df_with_label[\"failureType\"].unique())\ndf_with_label.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.774729Z","iopub.status.idle":"2023-03-31T02:38:10.775432Z","shell.execute_reply.started":"2023-03-31T02:38:10.775206Z","shell.execute_reply":"2023-03-31T02:38:10.775228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class2idx = {\n    'Loc': 0,\n    'Edge-Loc': 1,\n    'Center': 2,\n    'Edge-Ring': 3, \n    'Scratch': 4,\n    'Random': 5, \n    'Near-full': 6,\n    'Donut': 7\n}\nidx2class = {v: k for k, v in class2idx.items()}\n\n# The following needs only when you want to save the dict above. Not always necessary.\nclass2idx_json_path = \"./config_class2idx.json\"\nwith open(class2idx_json_path, \"w\") as f:\n    json.dump(class2idx, f)\n# ↑保存終了\n\n# New column → encoded_labels\ndf_with_label[\"encoded_labels\"] = df_with_label[\"failureType\"].replace(class2idx)\n\nprint(df_with_label[\"encoded_labels\"].value_counts())\ndf_with_label.reset_index(inplace=True, drop=True)\ndf_with_label.to_pickle(\"./LSWMD_25519.pkl\")  # ラベル有データ。ラベルエンコーディング等の前処理終わりデータになった。\ndf_with_label.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.776683Z","iopub.status.idle":"2023-03-31T02:38:10.777383Z","shell.execute_reply.started":"2023-03-31T02:38:10.777152Z","shell.execute_reply":"2023-03-31T02:38:10.777173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_length = int(0.8*len(df_with_label))  # training data for 80% of all data\ndf_with_label = df_with_label.sample(frac=1, random_state=2)\ndf_train, df_test = df_with_label[:train_data_length], df_with_label[train_data_length:]\ndf_train.reset_index(inplace=True, drop=True)\ndf_test.reset_index(inplace=True, drop=True)\n\ntrain_data_length = int(0.7*len(df_train))  # Again, split the train data: train ⇨ train & val\ndf_train, df_val = df_train[:train_data_length], df_train[train_data_length:]\nprint(f\"training: {len(df_train)}, val: {len(df_val)}, test: {len(df_test)}, (all: {len(df_with_label)})\")\n\n# This aims to save the data into your environment.\ndf_train.to_pickle(\"dataset_train.pickle\")\ndf_val.to_pickle(\"dataset_val.pickle\")\ndf_test.to_pickle(\"dataset_test.pickle\")\nprint(os.listdir())","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.778665Z","iopub.status.idle":"2023-03-31T02:38:10.779397Z","shell.execute_reply.started":"2023-03-31T02:38:10.779169Z","shell.execute_reply":"2023-03-31T02:38:10.779192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.780632Z","iopub.status.idle":"2023-03-31T02:38:10.781318Z","shell.execute_reply.started":"2023-03-31T02:38:10.781095Z","shell.execute_reply":"2023-03-31T02:38:10.781117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx2class = {v: k for k, v in class2idx.items()}\nbatch_size = 32\nplt.figure(figsize=(12,12))\nfor i in range(batch_size):\n    ax = plt.subplot(4, 8, i+1)\n    ax.axis(\"off\")\n    ax.imshow(df_train[\"waferMap\"][i])\n    ax.set_title(f'{idx2class[df_train[\"encoded_labels\"][i]]}:{str(df_train[\"encoded_labels\"][i])}', fontsize=8)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.782541Z","iopub.status.idle":"2023-03-31T02:38:10.783204Z","shell.execute_reply.started":"2023-03-31T02:38:10.782981Z","shell.execute_reply":"2023-03-31T02:38:10.783003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preprocess ended! 前処理終了\n# Model definition、Training\n- Simple model definition \n- Implement with `pytorch-metric-learning` library","metadata":{}},{"cell_type":"code","source":"!pip install pytorch-metric-learning==1.6.2\n# !pip install -q pytorch-metric-learning[with-hooks]\n!pip install -q scanpy\n!pip install faiss-cpu","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.784408Z","iopub.status.idle":"2023-03-31T02:38:10.785072Z","shell.execute_reply.started":"2023-03-31T02:38:10.784855Z","shell.execute_reply":"2023-03-31T02:38:10.784877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Any, List\nimport torch\nimport torchvision\nfrom torch import optim \nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport torch.nn.functional as F\nfrom pytorch_metric_learning import losses, miners, distances, reducers, samplers\nfrom pytorch_metric_learning import trainers, testers\nfrom pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\nfrom pytorch_metric_learning.utils import logging_presets\nimport cv2\nimport umap","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.786306Z","iopub.status.idle":"2023-03-31T02:38:10.786965Z","shell.execute_reply.started":"2023-03-31T02:38:10.786757Z","shell.execute_reply":"2023-03-31T02:38:10.786779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dataset class definition\nclass WafermapTripletDataset(Dataset):\n    def __init__(self, \n                 dataset_path: str = \"\",\n                 column_name_apply_wafermap = \"waferMap\",\n                 column_name_label: str = \"encoded_labels\",\n                 resized_image_size: int = 80,\n                 transforms: Any = None,\n                 phase: str = \"train\"):\n        super().__init__()\n        self.__dict__.update(locals())  # 個人的にはあまり好きな書き方ではない。1つずつ定義を書いてもいいと思う。\n        self._init_dataset()\n        self.transforms = transforms\n        self.phase = phase \n    \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        apply_wafermap, label = self.apply_wafer_maps[index], self.labels[index]\n        if self.transforms:\n            apply_wafermap = self.transforms(apply_wafermap, self.phase)\n        else:\n            pass\n        apply_wafermap = apply_wafermap.to(torch.float32)\n\n        return (apply_wafermap, label)\n\n    def _init_dataset(self):\n        self.df = pd.read_pickle(self.dataset_path).reset_index()\n        self.labels = self.df[self.column_name_label]\n\n        # modify wafermaps\n        # apply image\n        self.df[self.column_name_apply_wafermap] = self.df[self.column_name_apply_wafermap].apply(lambda x: cv2.resize(x, (self.resized_image_size, self.resized_image_size)))\n        self.df[self.column_name_apply_wafermap] = self.df[self.column_name_apply_wafermap].apply(lambda x: np.repeat(x[..., np.newaxis], 1, -1))\n        self.apply_wafer_maps = self.df[self.column_name_apply_wafermap].apply(lambda x: x.transpose((2,1,0)))  # inputの(バッチ、チャネル、たて、よこ)順番調整\n        self.apply_wafer_maps = self.apply_wafer_maps + 1e-6\n        self.apply_wafer_maps = self.apply_wafer_maps.apply(lambda x: torch.from_numpy(x))","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.788258Z","iopub.status.idle":"2023-03-31T02:38:10.788915Z","shell.execute_reply.started":"2023-03-31T02:38:10.788710Z","shell.execute_reply":"2023-03-31T02:38:10.788732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 1, 1)\n        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n        self.dropout1 = nn.Dropout2d(0.25)\n        self.dropout2 = nn.Dropout2d(0.25)\n        self.fc = nn.Linear(18432, 1152)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = self.conv3(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.dropout1(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        x = F.relu(x)\n        x = self.dropout2(x)\n        return x\n\n\nclass Embedder(nn.Module):\n    def __init__(self):\n        super(Embedder, self).__init__()\n        self.fc = nn.Linear(1152, 128)\n\n    def forward(self, x):\n        x = self.fc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.790101Z","iopub.status.idle":"2023-03-31T02:38:10.790747Z","shell.execute_reply.started":"2023-03-31T02:38:10.790510Z","shell.execute_reply":"2023-03-31T02:38:10.790538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# load the model\ntrunk = Net()\ntrunk = torch.nn.DataParallel(trunk.to(device))\nembedder = Embedder()\nembedder = torch.nn.DataParallel(embedder.to(device))\nmodels = {\"trunk\": trunk, \"embedder\": embedder} \n\n# optimizer setting\ntrunk_optimizer = optim.Adam(trunk.parameters(), lr=0.01)\nembedder_optimizer = optim.Adam(embedder.parameters(), lr=0.005)\noptimizers = {\"trunk_optimizer\": trunk_optimizer, \n              \"embedder_optimizer\": embedder_optimizer}\n\ndistance = distances.CosineSimilarity()\nreducer = reducers.ThresholdReducer(low=0) # 1対のペアごとにロスが計算されるが、揃ったものすべてを使うのではなく一定の閾値以上のものだけ使おうという処理。組み合わせ多いからかな。\nloss = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\nminer = miners.TripletMarginMiner(margin=0.2, distance=distance, type_of_triplets=\"semihard\")  # ペアのうち、semihardとなるものを探す(=mining)機能。ここも調整の余地あり\nloss_funcs = {\"metric_loss\": loss}\nmining_funcs = {\"tuple_miner\": miner}\n\n# visual_hook implementation for result visualization\nrecord_keeper, _, _ = logging_presets.get_record_keeper(\"logs\", \"tensorboard\")  # ログ機能。logs, tensorboardフォルダを作って色々格納してくれるが本筋に影響なし\nprint(f\"{record_keeper}\")\nhooks = logging_presets.get_hook_container(record_keeper)  # 学習イテレーションごとに追加処理を行うときに使う（embeddingをプロットしたい、）\n\ndef visualizer_hook(umapper, umap_embeddings, labels, split_name, keyname, epoch):\n    class_labels = np.unique(labels)\n    num_classes = len(class_labels)\n\n    fig = plt.figure(figsize=(8, 6))\n    colors = [plt.cm.nipy_spectral(i) for i in np.linspace(0, 0.9, num_classes)]\n    plt.gca().set_prop_cycle(cycler(\"color\", colors))\n\n    for i, lab in enumerate(class_labels):\n        idx = labels == class_labels[i]\n        plt.plot(umap_embeddings[idx, 0], umap_embeddings[idx, 1], \".\", markersize=3, label=lab) \n\n    plt.legend(frameon=False, fontsize=12, bbox_to_anchor=(1.05, 1), loc='upper left')\n    os.makedirs(\"result\", exist_ok=True)\n    plt.savefig(f\"result/{epoch:02d}.png\")\n    plt.show()\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.792329Z","iopub.status.idle":"2023-03-31T02:38:10.792742Z","shell.execute_reply.started":"2023-03-31T02:38:10.792541Z","shell.execute_reply":"2023-03-31T02:38:10.792560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train_path = \"./dataset_train.pickle\"\ndataset_val_path = \"./dataset_train.pickle\"\ndataset_test_path = \"./dataset_test.pickle\"\ntrain_dataset = WafermapTripletDataset(dataset_train_path, resized_image_size=28, column_name_apply_wafermap=\"waferMap\")\nval_dataset = WafermapTripletDataset(dataset_val_path, resized_image_size=28, column_name_apply_wafermap=\"waferMap\")\ntest_dataset = WafermapTripletDataset(dataset_test_path, resized_image_size=28, column_name_apply_wafermap=\"waferMap\")","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.793938Z","iopub.status.idle":"2023-03-31T02:38:10.794361Z","shell.execute_reply.started":"2023-03-31T02:38:10.794141Z","shell.execute_reply":"2023-03-31T02:38:10.794160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tester definition\ntester = testers.GlobalEmbeddingSpaceTester(end_of_testing_hook=hooks.end_of_testing_hook, \n                                            visualizer=umap.UMAP(), \n                                            visualizer_hook=visualizer_hook,\n                                            dataloader_num_workers=4)\n\n# Hook setting　→　1 epochごとにやってくれる処理をまとめるモジュールと考えればOK\ndataset_dict = {\"val\": val_dataset}\nmodel_dir = \"./saved_models\"\nend_of_epoch_hook = hooks.end_of_epoch_hook(tester, \n                                            dataset_dict, \n                                            model_dir, \n#                                             test_interval=1,   # depending on the PML version, this might be an error\n#                                             patience=1,  # depending on the PML version, this might be an error\n                                           )\n\n# Model training\nnum_epochs = 50\nbatch_size = 48\n\n# PML training API：trainer　⇒　モデル、ロス、最適化関数、データセットクラス、マイニング関数、等を与える\ntrainer = trainers.MetricLossOnly(models,\n                                  optimizers,\n                                  batch_size,\n                                  loss_funcs,\n                                  mining_funcs,\n                                  train_dataset,\n                                #   sampler=sampler,\n                                  dataloader_num_workers=4,\n                                  end_of_iteration_hook=hooks.end_of_iteration_hook,\n                                  end_of_epoch_hook=end_of_epoch_hook)\ntrainer.train(num_epochs=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.796117Z","iopub.status.idle":"2023-03-31T02:38:10.796541Z","shell.execute_reply.started":"2023-03-31T02:38:10.796336Z","shell.execute_reply":"2023-03-31T02:38:10.796355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# you can plot learning history, but it seems to depend on PML version. I am trying.\n\n# loss_history = hooks.get_loss_history()\n# plt.plot(loss_history[\"metric_loss\"], \"r\", alpha=0.6, label=\"loss\")\n# plt.legend()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.798517Z","iopub.status.idle":"2023-03-31T02:38:10.799290Z","shell.execute_reply.started":"2023-03-31T02:38:10.799051Z","shell.execute_reply":"2023-03-31T02:38:10.799073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference(Image Retrieval) 推論（画像検索）\n- Load the model\n- `InferenceModel`(pytorch-metric-learning module) ⇨ executes nearest neighbor search","metadata":{}},{"cell_type":"code","source":"from pytorch_metric_learning.distances import CosineSimilarity\nfrom pytorch_metric_learning.utils import common_functions as c_f\nfrom pytorch_metric_learning.utils.inference import InferenceModel, MatchFinder\n\n\n# saved_trunk_path = \"./saved_models/trunk_best1.pth\"\n# saved_embedder_path = \"./saved_models/embedder_best1.pth\"\n\n# trunk = Net()\n# trunk.load_state_dict(torch.load(saved_trunk_path))\n# trunk.cpu()\n\n# embedder = Embedder()\n# embedder.load_state_dict(torch.load(saved_embedder_path))\n# embedder.cpu()\n\nmatch_finder = MatchFinder(distance=CosineSimilarity(), threshold=0.7)\ninference_model = InferenceModel(trunk=trunk,\n                                 embedder=embedder,\n                                 match_finder=match_finder,\n                                 data_device=\"cpu\",\n                                 )","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.800928Z","iopub.status.idle":"2023-03-31T02:38:10.801368Z","shell.execute_reply.started":"2023-03-31T02:38:10.801136Z","shell.execute_reply":"2023-03-31T02:38:10.801156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# knn!(knn way nearest neighbor search)： This makes indices of the dataset\ninference_model.train_knn(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.802858Z","iopub.status.idle":"2023-03-31T02:38:10.803784Z","shell.execute_reply.started":"2023-03-31T02:38:10.803570Z","shell.execute_reply":"2023-03-31T02:38:10.803592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# データセットクラスで定義したラベル（0－7）それぞれに対応するインデックスを取得できる\n# PML offeres some utils function. You can get the data separated by labels.\nlabels_to_indices = c_f.get_labels_to_indices(test_dataset.labels)\n# 試しにラベル3、ラベル６のインデックス集合をそれぞれ取得する\n# For example, let's get the data with label 3 & 6\nclassA, classB = labels_to_indices[3], labels_to_indices[6]\nimg_type = classA   # ラベル3に対応するインデックスの集合(Data with label '3')\n\n# 検索実行 Let's retrieve!\nimg, label = test_dataset[img_type[2]][0].unsqueeze(0), test_dataset[img_type[2]][1]\nprint(type(img), img.shape)\n\ntop_k = 10\ndistances, indices = inference_model.get_nearest_neighbors(img, k=top_k)\ndistances_list = list(distances.cpu().numpy()[0])\nindices_list = list(indices.cpu().numpy()[0])","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.805327Z","iopub.status.idle":"2023-03-31T02:38:10.806176Z","shell.execute_reply.started":"2023-03-31T02:38:10.805948Z","shell.execute_reply":"2023-03-31T02:38:10.805971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"top'{top_k}' index: \", indices_list)\ndf_result = test_dataset.df.iloc[indices_list, :]\ndf_result.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.807823Z","iopub.status.idle":"2023-03-31T02:38:10.808562Z","shell.execute_reply.started":"2023-03-31T02:38:10.808350Z","shell.execute_reply":"2023-03-31T02:38:10.808372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiment Results, 実験結果\n先ほどやったことを視覚化しながら再度実行してみる\n- Comparison of query image and retrieved ones\n- Visualize the embedding space(On kaggle notebook, it doesn't work. You can download it and try on the other environment)","metadata":{}},{"cell_type":"code","source":"# クエリ情報の抜出 (ラベル１のデータを抜き出し、とりあえず最初の行にあるものをクエリとしてみる)\nencoded_label = 4  # 自由に変えてトライ, Let's change.\ndf_tmp = test_dataset.df.query(f\"encoded_labels=={encoded_label}\").reset_index()\nquery, query_label = df_tmp[\"waferMap\"][0], df_tmp[\"encoded_labels\"][0]\nprint(\"Before preprocess: \", type(query), query.shape) # この時点ではnumpy.ndarrayになっている\nplt.imshow(query)\nplt.title(f\"Query image: {idx2class[query_label]}\")\n\n\n# クエリ画像をモデルに入力するためのtorch用前処理\nquery = query.transpose(2,0,1) # shape:(a,b,c) → (c,a,b)\nquery = torch.from_numpy(query).float()\nquery = query.unsqueeze(0) # shape:(a,b,c) → (1,a,b,c) のように1を追加。PyTorchのお作法（バッチ次元）\nprint(\"After preprocess: \", type(query), query.shape) # この時点ではtorch.Tensorになっている\nassert isinstance(query, torch.Tensor)\n\n# Search! 実験（検索実行！）\ntop_k = 10\ndistances, indices = inference_model.get_nearest_neighbors(query, k=top_k)\ndistances_list = list(distances.cpu().numpy()[0])\nindices_list = list(indices.cpu().numpy()[0])\n\nprint(f\"top'{top_k}' index: \", indices_list)\ndf_result = test_dataset.df.iloc[indices_list, :].reset_index(drop=True)\n\n\n# Visualize results. 結果表示\ndisplay(df_result.head(10))\nplt.figure(figsize=(16,16))\nfor i in range(top_k):\n    ax = plt.subplot(8, 6, i+1)\n    ax.axis(\"off\")\n    ax.imshow(df_result[\"waferMap\"][i])\n    ax.set_title(f'{idx2class[df_result[\"encoded_labels\"][i]]}-{str(df_result[\"encoded_labels\"][i])}', \n                 fontsize=8,\n                )\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.810210Z","iopub.status.idle":"2023-03-31T02:38:10.810680Z","shell.execute_reply.started":"2023-03-31T02:38:10.810472Z","shell.execute_reply":"2023-03-31T02:38:10.810493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 以上,結果のまとめと今後とるべき対策\n- クエリに対して画像の検索を実施した\n- クエリに対して検索上位に出てきたものは似てるものだけではなかった。\n    * 学習器を変える\n    * 画像毎のサイズ違いに注意する\n    * augmentationする\n\n## 発展的知識\n- プロダクション上では一般に検索DBが大きくなりやすい（桁違いに大きくなる）\n- クエリの特徴量抽出は特徴抽出器のサイズ依存だが、検索は「検索手法依存」となる\n- 検索には一定の高速性が求められるため、「検索手法」の工夫が世の中にはたくさんある\n    * 全探索手法\n    * 最近傍探索手法\n    * 近似最近傍探索手法\n    * 様々な後処理手法（検索結果を出したのち、その中で再度何かしら計算を行い精度を高める）\n- 画像検索は「クエリと似たものは何か？」を探すタスクであり、学習時にないデータを推論する（=検索する）ことに使う\n- metric learningは学習データの**相対的な位置関係**をロス関数にして学習しており、顔認証や画像検索タスクに用いられることで知られる（世の中のどのシステムに具体的に導入されてるかは把握してません）\n- 画像検索コンペの最上位でもmetric learningは未だに使用されており、工夫はいるが強力な手法である","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 以下、ちょっとわからないこと出たのでやりません。機能だけ紹介します。\n\n再度掲載- クラスと対応番号\n```\nclass2idx = {\n    'Loc': 0,\n    'Edge-Loc': 1,\n    'Center': 2,\n    'Edge-Ring': 3, \n    'Scratch': 4,\n    'Random': 5, \n    'Near-full': 6,\n    'Donut': 7\n}\n```","metadata":{}},{"cell_type":"code","source":"# データセットクラスで定義したラベル（0－7）それぞれに対応するインデックスを取得できる\nlabels_to_indices = c_f.get_labels_to_indices(train_dataset.labels)\n# 試しにラベル１、ラベル６のインデックス集合をそれぞれ取得する\nclassA, classB = labels_to_indices[3], labels_to_indices[9]\nimg_type = classA   # ラベル3に対応するインデックスの集合\n\n# 検索実行\nimg, label = test_dataset[img_type[2]][0].unsqueeze(0), test_dataset[img_type[2]][1]\nprint(type(img), img.shape)\n# distances, indices = inference_model.get_nearest_neighbors(img, k=10)\n\nprint(classA)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.812368Z","iopub.status.idle":"2023-03-31T02:38:10.813192Z","shell.execute_reply.started":"2023-03-31T02:38:10.812980Z","shell.execute_reply":"2023-03-31T02:38:10.813003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(indices.cpu().numpy())\nprint(indices.cpu().numpy()[0].shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.814772Z","iopub.status.idle":"2023-03-31T02:38:10.815585Z","shell.execute_reply.started":"2023-03-31T02:38:10.815345Z","shell.execute_reply":"2023-03-31T02:38:10.815371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_decision(is_match):\n    if is_match:\n        print(\"Same class\")\n    else:\n        print(\"Different class\")\n\n# mean = [0.485, 0.456, 0.406]\n# std = [0.229, 0.224, 0.225]\n\n# inv_normalize = transforms.Normalize(\n#     mean=[-m / s for m, s in zip(mean, std)], std=[1 / s for s in std]\n# )\ndef imshow(img, title=None, figsize=(8, 4)):\n    # img = inv_normalize(img)\n    npimg = img.numpy()\n    plt.figure(figsize=figsize)\n    plt.imshow(np.transpose(npimg, (1, 2, 0))[:,:,0])\n    plt.title(title)\n    plt.show()\n\n# compare two images of the same class\n(x, _), (y, _) = test_dataset[classA[0]], test_dataset[classA[1]]\nprint(x.shape, y.shape)\ndecision = inference_model.is_match(x.unsqueeze(0), y.unsqueeze(0))\nstack_image = torch.stack([x, y], dim=0)  # double torch.Size([20, 1, 28, 28]) -> torch.Size([2, 20, 1, 28, 28])\nimshow(torchvision.utils.make_grid(stack_image), title=decision)\nprint_decision(decision)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T02:38:10.817209Z","iopub.status.idle":"2023-03-31T02:38:10.817652Z","shell.execute_reply.started":"2023-03-31T02:38:10.817451Z","shell.execute_reply":"2023-03-31T02:38:10.817470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}